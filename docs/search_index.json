[["preprocessing-imc-data.html", "Chapter 3 Preprocessing IMC data 3.1 Read in the data 3.2 Generate a spillover matrix 3.3 Optional binning", " Chapter 3 Preprocessing IMC data To test the scripts, please access the raw data via: sm_url &lt;- &quot;https://data.mendeley.com/public-files/datasets/v58yj49pfr/files/b39223d2-2825-4e79-9875-86fa0e1c55d2/file_downloaded?dl=1&quot; download.file(sm_url, &quot;data/Figure_S5.zip&quot;) unzip(&quot;data/Figure_S5.zip&quot;, exdir=&quot;data&quot;, overwrite=TRUE) unlink(&quot;data/Figure_S5.zip&quot;) 3.1 Read in the data Overview on how to read in pre-processed data. 3.2 Generate a spillover matrix In this section, we will highlight the use of imcRtools and CATALYST to generate a spillover matrix for IMC data. 3.2.1 Read in the data First, we need to read in the txt files. library(tidyverse) # Read txt files cur_txts_names &lt;- list.files(&quot;data/Figure_S5/Spillover_Matrix_1/&quot;, full.names = TRUE) cur_txts &lt;- lapply(cur_txts_names, read_delim, delim = &quot;\\t&quot;) names(cur_txts) &lt;- str_match(cur_txts_names, &quot;[A-Za-z]{2}[0-9]{2,3}&quot;) 3.2.2 Quality control Visualize median expression library(pheatmap) library(viridis) library(matrixStats) cur_medians &lt;- lapply(cur_txts, function(x){ cur_txt &lt;- x %&gt;% select(-c(Start_push, End_push, Pushes_duration, X, Y, Z)) cur_m &lt;- colMedians(as.matrix(cur_txt)) names(cur_m) &lt;- colnames(cur_txt) return(cur_m) }) cur_medians &lt;- do.call(rbind, cur_medians) # Order matrix by metal cur_medians &lt;- cur_medians[order(as.numeric(str_match(rownames(cur_medians), &quot;[0-9]{2,3}&quot;))), order(as.numeric(str_match(colnames(cur_medians), &quot;[0-9]{2,3}&quot;)))] pheatmap(log10(cur_medians + 1), cluster_rows = FALSE, cluster_cols = FALSE, color = viridis(100)) # Visualize a threshold - multiplication with 1 to change logical to numeric pheatmap(1 * (cur_medians &gt; 200), cluster_rows = FALSE, cluster_cols = FALSE) 3.3 Optional binning If the signals are too low, pixels can be summed: library(zoo) bin_size = 10 cur_txts_binned &lt;- lapply(cur_txts, function(x){ cur_txt &lt;- x %&gt;% select(-c(Start_push, End_push, Pushes_duration, X, Y, Z)) %&gt;% as.matrix() cur_txt &lt;- apply(cur_txt, 2, function(y){rollapply(y, width = bin_size, FUN = sum, by = bin_size)}) return(cur_txt) }) cur_medians &lt;- lapply(cur_txts_binned, function(x){ cur_m &lt;- colMedians(as.matrix(x)) names(cur_m) &lt;- colnames(x) return(cur_m) }) cur_medians &lt;- do.call(rbind, cur_medians) # Order matrix by metal cur_medians &lt;- cur_medians[order(as.numeric(str_match(rownames(cur_medians), &quot;[0-9]{2,3}&quot;))), order(as.numeric(str_match(colnames(cur_medians), &quot;[0-9]{2,3}&quot;)))] pheatmap(log10(cur_medians + 1), cluster_rows = FALSE, cluster_cols = FALSE, color = viridis(100)) # Visualize a threshold - multiplication with 1 to change logical to numeric pheatmap(1 * (cur_medians &gt; 200), cluster_rows = FALSE, cluster_cols = FALSE) 3.3.1 Format the SingleCellExperiment Here, we will reformat the raw data into a SingleCellExperiment container that can be used with CATALYST. library(CATALYST) ## Loading required package: SingleCellExperiment ## Loading required package: SummarizedExperiment ## Loading required package: MatrixGenerics ## ## Attaching package: &#39;MatrixGenerics&#39; ## The following objects are masked from &#39;package:matrixStats&#39;: ## ## colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse, ## colCounts, colCummaxs, colCummins, colCumprods, colCumsums, ## colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs, ## colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats, ## colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds, ## colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads, ## colWeightedMeans, colWeightedMedians, colWeightedSds, ## colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet, ## rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods, ## rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps, ## rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins, ## rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks, ## rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars, ## rowWeightedMads, rowWeightedMeans, rowWeightedMedians, ## rowWeightedSds, rowWeightedVars ## Loading required package: GenomicRanges ## Loading required package: stats4 ## Loading required package: BiocGenerics ## Loading required package: parallel ## ## Attaching package: &#39;BiocGenerics&#39; ## The following objects are masked from &#39;package:parallel&#39;: ## ## clusterApply, clusterApplyLB, clusterCall, clusterEvalQ, ## clusterExport, clusterMap, parApply, parCapply, parLapply, ## parLapplyLB, parRapply, parSapply, parSapplyLB ## The following objects are masked from &#39;package:dplyr&#39;: ## ## combine, intersect, setdiff, union ## The following objects are masked from &#39;package:stats&#39;: ## ## IQR, mad, sd, var, xtabs ## The following objects are masked from &#39;package:base&#39;: ## ## anyDuplicated, append, as.data.frame, basename, cbind, colnames, ## dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep, ## grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget, ## order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank, ## rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply, ## union, unique, unsplit, which.max, which.min ## Loading required package: S4Vectors ## ## Attaching package: &#39;S4Vectors&#39; ## The following objects are masked from &#39;package:dplyr&#39;: ## ## first, rename ## The following object is masked from &#39;package:tidyr&#39;: ## ## expand ## The following object is masked from &#39;package:base&#39;: ## ## expand.grid ## Loading required package: IRanges ## ## Attaching package: &#39;IRanges&#39; ## The following objects are masked from &#39;package:dplyr&#39;: ## ## collapse, desc, slice ## The following object is masked from &#39;package:purrr&#39;: ## ## reduce ## Loading required package: GenomeInfoDb ## Loading required package: Biobase ## Welcome to Bioconductor ## ## Vignettes contain introductory material; view with ## &#39;browseVignettes()&#39;. To cite Bioconductor, see ## &#39;citation(&quot;Biobase&quot;)&#39;, and for packages &#39;citation(&quot;pkgname&quot;)&#39;. ## ## Attaching package: &#39;Biobase&#39; ## The following object is masked from &#39;package:MatrixGenerics&#39;: ## ## rowMedians ## The following objects are masked from &#39;package:matrixStats&#39;: ## ## anyMissing, rowMedians cur_counts &lt;- do.call(rbind, cur_txts) %&gt;% select(-c(Start_push, End_push, Pushes_duration, X, Y, Z)) %&gt;% rename_with(~ str_match(string = .x, pattern = &quot;[A-Za-z]{2}[0-9]{2,3}Di&quot;)) %&gt;% as.matrix() sce &lt;- SingleCellExperiment(assays = list(counts = t(cur_counts), exprs = t(asinh(cur_counts/5)))) rowData(sce) &lt;- DataFrame(channel_name = rownames(sce), marker_name = rownames(sce)) colData(sce) &lt;- DataFrame(sample_id = rep(names(cur_txts), times = sapply(cur_txts, nrow))) sce$sample_mass &lt;- str_match(sce$sample_id, pattern = &quot;[0-9]{2,3}&quot;) sce &lt;- assignPrelim(sce, bc_key = as.numeric(str_match(rownames(sce), pattern = &quot;[0-9]{2,3}&quot;))) ## Debarcoding data... ## o ordering ## o classifying events ## Normalizing... ## Computing deltas... sce &lt;- estCutoffs(sce) sce &lt;- applyCutoffs(sce) 3.3.2 Remove pixels with incorrect labels and stains with few correctly identified pixels # Remove incorrectly labelled pixels sce$bc_id[sce$bc_id != 0 &amp; sce$bc_id != sce$sample_mass] &lt;- 0 # Remove small populations - not applicable in this dataset minevent &lt;- 40 cur_stats &lt;- table(sce$bc_id) nonfreq &lt;- names(cur_stats)[cur_stats &lt; minevent] sce$bc_id[sce$bc_id %in% nonfreq] &lt;- 0 3.3.3 Compute spillover matrix sce &lt;- computeSpillmat(sce) plotSpillmat(sce) 3.3.4 Save spillover matrix as csv Next, we will write out the spillover matrix as csv. 3.3.5 Save spillover matrix as image 3.3.6 Sanity check that spillover matrix is correct correct_sm &lt;- read.csv(&quot;data/Figure_S5/paper_version_Spillover_Matrix_1_sm.csv&quot;) rownames(correct_sm) &lt;- correct_sm[,1] correct_sm &lt;- as.matrix(correct_sm[,-1]) current_sm &lt;- metadata(sce)$spillover_matrix current_sm &lt;- current_sm[rownames(correct_sm),colnames(correct_sm)] stopifnot(all.equal(correct_sm, current_sm, tolerance = 0.01)) "]]
